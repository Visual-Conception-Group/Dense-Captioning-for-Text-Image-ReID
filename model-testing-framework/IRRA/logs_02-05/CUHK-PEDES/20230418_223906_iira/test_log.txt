TEST:
2023-04-19 16:23:58,490 IRRA INFO: {'GPU_ID': 1, 'MLM': True, 'alpha': 0.9, 'batch_size': 64, 'beta': 0.999, 'bias_lr_factor': 2.0, 'cmt_depth': 4, 'dataset_name': 'CUHK-PEDES', 'distributed': False, 'eval_period': 1, 'gamma': 0.1, 'id_loss_weight': 1.0, 'img_aug': True, 'img_size': [384, 128], 'local_rank': 0, 'log_period': 100, 'loss_names': 'sdm+mlm+id', 'lr': 1e-05, 'lr_factor': 5.0, 'lrscheduler': 'cosine', 'masked_token_rate': 0.8, 'masked_token_unchanged_rate': 0.1, 'milestones': [20, 50], 'mlm_loss_weight': 1.0, 'momentum': 0.9, 'name': 'iira', 'num_epoch': 60, 'num_instance': 4, 'num_workers': 8, 'optimizer': 'Adam', 'output_dir': 'logs/CUHK-PEDES/20230418_223906_iira', 'power': 0.9, 'pretrain_choice': 'ViT-B/16', 'resume': False, 'resume_ckpt_file': '', 'root_dir': './data', 'sampler': 'random', 'stride_size': 16, 'target_lr': 0, 'temperature': 0.02, 'test_batch_size': 512, 'text_length': 77, 'training': False, 'val_dataset': 'val', 'vocab_size': 49408, 'warmup_epochs': 5, 'warmup_factor': 0.1, 'warmup_method': 'linear', 'weight_decay': 4e-05, 'weight_decay_bias': 0.0}
2023-04-19 16:23:59,176 IRRA.dataset INFO: => CUHK-PEDES Images and Captions are loaded
2023-04-19 16:23:59,176 IRRA.dataset INFO: CUHKPEDES Dataset statistics:
2023-04-19 16:23:59,177 IRRA.dataset INFO: 
+--------+-------+--------+----------+
| subset |  ids  | images | captions |
+--------+-------+--------+----------+
| train  | 11003 | 34054  |  68126   |
|  test  |  1000 |  3074  |   6156   |
|  val   |  1000 |  3078  |   6158   |
+--------+-------+--------+----------+
2023-04-19 16:24:00,149 IRRA.model INFO: Load pretrained ViT-B/16 CLIP model with model config: {'embed_dim': 512, 'image_resolution': [384, 128], 'vision_layers': 12, 'vision_width': 768, 'vision_patch_size': 16, 'context_length': 77, 'vocab_size': 49408, 'transformer_width': 512, 'transformer_heads': 8, 'transformer_layers': 12, 'stride_size': 16}
2023-04-19 16:24:05,875 IRRA.test INFO: Enter inferencing
2023-04-19 16:24:13,985 IRRA.eval INFO: 
+------+--------+--------+--------+--------+--------+
| task |   R1   |   R5   |  R10   |  mAP   |  mINP  |
+------+--------+--------+--------+--------+--------+
| t2i  | 73.684 | 89.864 | 93.746 | 66.405 | 50.602 |
+------+--------+--------+--------+--------+--------+

TEST (ICFG-PEDES):
2023-04-19 16:59:58,565 IRRA INFO: {'GPU_ID': 1, 'MLM': True, 'alpha': 0.9, 'batch_size': 64, 'beta': 0.999, 'bias_lr_factor': 2.0, 'cmt_depth': 4, 'dataset_name': 'ICFG-PEDES', 'distributed': False, 'eval_period': 1, 'gamma': 0.1, 'id_loss_weight': 1.0, 'img_aug': True, 'img_size': [384, 128], 'local_rank': 0, 'log_period': 100, 'loss_names': 'sdm+mlm', 'lr': 1e-05, 'lr_factor': 5.0, 'lrscheduler': 'cosine', 'masked_token_rate': 0.8, 'masked_token_unchanged_rate': 0.1, 'milestones': [20, 50], 'mlm_loss_weight': 1.0, 'momentum': 0.9, 'name': 'iira', 'num_epoch': 60, 'num_instance': 4, 'num_workers': 8, 'optimizer': 'Adam', 'output_dir': 'logs/CUHK-PEDES/20230418_223906_iira', 'power': 0.9, 'pretrain_choice': 'ViT-B/16', 'resume': False, 'resume_ckpt_file': '', 'root_dir': './data', 'sampler': 'random', 'stride_size': 16, 'target_lr': 0, 'temperature': 0.02, 'test_batch_size': 512, 'text_length': 77, 'training': False, 'val_dataset': 'val', 'vocab_size': 49408, 'warmup_epochs': 5, 'warmup_factor': 0.1, 'warmup_method': 'linear', 'weight_decay': 4e-05, 'weight_decay_bias': 0.0}
2023-04-19 16:59:59,540 IRRA.dataset INFO: => ICFG-PEDES Images and Captions are loaded
2023-04-19 16:59:59,540 IRRA.dataset INFO: ICFGPEDES Dataset statistics:
2023-04-19 16:59:59,542 IRRA.dataset INFO: 
+--------+------+--------+----------+
| subset | ids  | images | captions |
+--------+------+--------+----------+
| train  | 3102 | 34674  |  34674   |
|  test  | 1000 | 19848  |  19848   |
|  val   |  0   |   0    |    0     |
+--------+------+--------+----------+
2023-04-19 17:00:00,616 IRRA.model INFO: Load pretrained ViT-B/16 CLIP model with model config: {'embed_dim': 512, 'image_resolution': [384, 128], 'vision_layers': 12, 'vision_width': 768, 'vision_patch_size': 16, 'context_length': 77, 'vocab_size': 49408, 'transformer_width': 512, 'transformer_heads': 8, 'transformer_layers': 12, 'stride_size': 16}
2023-04-19 17:00:06,654 IRRA.test INFO: Enter inferencing
2023-04-19 17:00:40,876 IRRA.eval INFO: 
+------+--------+--------+--------+--------+-------+
| task |   R1   |   R5   |  R10   |  mAP   |  mINP |
+------+--------+--------+--------+--------+-------+
| t2i  | 43.133 | 62.500 | 70.022 | 22.367 | 2.100 |
+------+--------+--------+--------+--------+-------+

TEST (RSTPReid):
2023-04-19 17:02:49,197 IRRA INFO: {'GPU_ID': 1, 'MLM': True, 'alpha': 0.9, 'batch_size': 64, 'beta': 0.999, 'bias_lr_factor': 2.0, 'cmt_depth': 4, 'dataset_name': 'RSTPReid', 'distributed': False, 'eval_period': 1, 'gamma': 0.1, 'id_loss_weight': 1.0, 'img_aug': True, 'img_size': [384, 128], 'local_rank': 0, 'log_period': 100, 'loss_names': 'sdm+mlm', 'lr': 1e-05, 'lr_factor': 5.0, 'lrscheduler': 'cosine', 'masked_token_rate': 0.8, 'masked_token_unchanged_rate': 0.1, 'milestones': [20, 50], 'mlm_loss_weight': 1.0, 'momentum': 0.9, 'name': 'iira', 'num_epoch': 60, 'num_instance': 4, 'num_workers': 8, 'optimizer': 'Adam', 'output_dir': 'logs/CUHK-PEDES/20230418_223906_iira', 'power': 0.9, 'pretrain_choice': 'ViT-B/16', 'resume': False, 'resume_ckpt_file': '', 'root_dir': './data', 'sampler': 'random', 'stride_size': 16, 'target_lr': 0, 'temperature': 0.02, 'test_batch_size': 512, 'text_length': 77, 'training': False, 'val_dataset': 'val', 'vocab_size': 49408, 'warmup_epochs': 5, 'warmup_factor': 0.1, 'warmup_method': 'linear', 'weight_decay': 4e-05, 'weight_decay_bias': 0.0}
2023-04-19 17:02:49,311 IRRA.dataset INFO: => RSTPReid Images and Captions are loaded
2023-04-19 17:02:49,311 IRRA.dataset INFO: RSTPReid Dataset statistics:
2023-04-19 17:02:49,311 IRRA.dataset INFO: 
+--------+------+--------+----------+
| subset | ids  | images | captions |
+--------+------+--------+----------+
| train  | 3701 | 18505  |  37010   |
|  test  | 200  |  1000  |   2000   |
|  val   | 200  |  1000  |   2000   |
+--------+------+--------+----------+
2023-04-19 17:02:50,260 IRRA.model INFO: Load pretrained ViT-B/16 CLIP model with model config: {'embed_dim': 512, 'image_resolution': [384, 128], 'vision_layers': 12, 'vision_width': 768, 'vision_patch_size': 16, 'context_length': 77, 'vocab_size': 49408, 'transformer_width': 512, 'transformer_heads': 8, 'transformer_layers': 12, 'stride_size': 16}
2023-04-19 17:02:56,243 IRRA.test INFO: Enter inferencing
2023-04-19 17:03:02,486 IRRA.eval INFO: 
+------+--------+--------+--------+--------+--------+
| task |   R1   |   R5   |  R10   |  mAP   |  mINP  |
+------+--------+--------+--------+--------+--------+
| t2i  | 53.300 | 77.400 | 86.000 | 40.054 | 16.630 |
+------+--------+--------+--------+--------+--------+

TEST (IIITD):
2023-04-19 17:03:52,173 IRRA INFO: {'GPU_ID': 1, 'MLM': True, 'alpha': 0.9, 'batch_size': 64, 'beta': 0.999, 'bias_lr_factor': 2.0, 'cmt_depth': 4, 'dataset_name': 'IIITD', 'distributed': False, 'eval_period': 1, 'gamma': 0.1, 'id_loss_weight': 1.0, 'img_aug': True, 'img_size': [384, 128], 'local_rank': 0, 'log_period': 100, 'loss_names': 'sdm+mlm', 'lr': 1e-05, 'lr_factor': 5.0, 'lrscheduler': 'cosine', 'masked_token_rate': 0.8, 'masked_token_unchanged_rate': 0.1, 'milestones': [20, 50], 'mlm_loss_weight': 1.0, 'momentum': 0.9, 'name': 'iira', 'num_epoch': 60, 'num_instance': 4, 'num_workers': 8, 'optimizer': 'Adam', 'output_dir': 'logs/CUHK-PEDES/20230418_223906_iira', 'power': 0.9, 'pretrain_choice': 'ViT-B/16', 'resume': False, 'resume_ckpt_file': '', 'root_dir': './data', 'sampler': 'random', 'stride_size': 16, 'target_lr': 0, 'temperature': 0.02, 'test_batch_size': 512, 'text_length': 77, 'training': False, 'val_dataset': 'val', 'vocab_size': 49408, 'warmup_epochs': 5, 'warmup_factor': 0.1, 'warmup_method': 'linear', 'weight_decay': 4e-05, 'weight_decay_bias': 0.0}
2023-04-19 17:03:52,753 IRRA.dataset INFO: => IIITD Images and Captions are loaded
2023-04-19 17:03:52,753 IRRA.dataset INFO: IIITD Dataset statistics:
2023-04-19 17:03:52,754 IRRA.dataset INFO: 
+--------+-------+--------+----------+
| subset |  ids  | images | captions |
+--------+-------+--------+----------+
| train  | 15000 | 30000  |  30000   |
|  test  |  2500 |  5000  |   5000   |
|  val   |  2500 |  5000  |   5000   |
+--------+-------+--------+----------+
2023-04-19 17:03:53,779 IRRA.model INFO: Load pretrained ViT-B/16 CLIP model with model config: {'embed_dim': 512, 'image_resolution': [384, 128], 'vision_layers': 12, 'vision_width': 768, 'vision_patch_size': 16, 'context_length': 77, 'vocab_size': 49408, 'transformer_width': 512, 'transformer_heads': 8, 'transformer_layers': 12, 'stride_size': 16}
2023-04-19 17:03:59,766 IRRA.test INFO: Enter inferencing
2023-04-19 17:04:09,439 IRRA.eval INFO: 
+------+--------+--------+--------+--------+--------+
| task |   R1   |   R5   |  R10   |  mAP   |  mINP  |
+------+--------+--------+--------+--------+--------+
| t2i  | 64.560 | 82.280 | 87.060 | 72.840 | 74.712 |
+------+--------+--------+--------+--------+--------+


I2T testing:


TEST:
2023-04-23 02:50:08,946 IRRA INFO: {'GPU_ID': 7, 'MLM': True, 'alpha': 0.9, 'batch_size': 64, 'beta': 0.999, 'bias_lr_factor': 2.0, 'cmt_depth': 4, 'dataset_name': 'CUHK-PEDES', 'distributed': False, 'eval_period': 1, 'gamma': 0.1, 'id_loss_weight': 1.0, 'img_aug': True, 'img_size': [384, 128], 'local_rank': 0, 'log_period': 100, 'loss_names': 'sdm+mlm', 'lr': 1e-05, 'lr_factor': 5.0, 'lrscheduler': 'cosine', 'masked_token_rate': 0.8, 'masked_token_unchanged_rate': 0.1, 'milestones': [20, 50], 'mlm_loss_weight': 1.0, 'momentum': 0.9, 'name': 'iira', 'num_epoch': 60, 'num_instance': 4, 'num_workers': 8, 'optimizer': 'Adam', 'output_dir': 'logs/CUHK-PEDES/20230418_223906_iira', 'power': 0.9, 'pretrain_choice': 'ViT-B/16', 'resume': False, 'resume_ckpt_file': '', 'root_dir': './data', 'sampler': 'random', 'stride_size': 16, 'target_lr': 0, 'temperature': 0.02, 'test_batch_size': 512, 'text_length': 77, 'training': False, 'val_dataset': 'val', 'vocab_size': 49408, 'warmup_epochs': 5, 'warmup_factor': 0.1, 'warmup_method': 'linear', 'weight_decay': 4e-05, 'weight_decay_bias': 0.0}
2023-04-23 02:50:09,913 IRRA.dataset INFO: => CUHK-PEDES Images and Captions are loaded
2023-04-23 02:50:09,913 IRRA.dataset INFO: CUHKPEDES Dataset statistics:
2023-04-23 02:50:09,913 IRRA.dataset INFO: 
+--------+-------+--------+----------+
| subset |  ids  | images | captions |
+--------+-------+--------+----------+
| train  | 11003 | 34054  |  68126   |
|  test  |  1000 |  3074  |   6156   |
|  val   |  1000 |  3078  |   6158   |
+--------+-------+--------+----------+
2023-04-23 02:50:11,058 IRRA.model INFO: Load pretrained ViT-B/16 CLIP model with model config: {'embed_dim': 512, 'image_resolution': [384, 128], 'vision_layers': 12, 'vision_width': 768, 'vision_patch_size': 16, 'context_length': 77, 'vocab_size': 49408, 'transformer_width': 512, 'transformer_heads': 8, 'transformer_layers': 12, 'stride_size': 16}
2023-04-23 02:50:16,993 IRRA.test INFO: Enter inferencing
2023-04-23 02:50:29,947 IRRA.eval INFO: 
+------+--------+--------+--------+--------+--------+
| task |   R1   |   R5   |  R10   |  mAP   |  mINP  |
+------+--------+--------+--------+--------+--------+
| t2i  | 73.684 | 89.864 | 93.746 | 66.405 | 50.602 |
| i2t  | 85.491 | 97.170 | 98.861 | 62.978 | 27.292 |
+------+--------+--------+--------+--------+--------+

TEST (ICFG-PEDES):
2023-04-23 02:54:39,575 IRRA INFO: {'GPU_ID': 0, 'MLM': True, 'alpha': 0.9, 'batch_size': 64, 'beta': 0.999, 'bias_lr_factor': 2.0, 'cmt_depth': 4, 'dataset_name': 'ICFG-PEDES', 'distributed': False, 'eval_period': 1, 'gamma': 0.1, 'id_loss_weight': 1.0, 'img_aug': True, 'img_size': [384, 128], 'local_rank': 0, 'log_period': 100, 'loss_names': 'sdm+mlm', 'lr': 1e-05, 'lr_factor': 5.0, 'lrscheduler': 'cosine', 'masked_token_rate': 0.8, 'masked_token_unchanged_rate': 0.1, 'milestones': [20, 50], 'mlm_loss_weight': 1.0, 'momentum': 0.9, 'name': 'iira', 'num_epoch': 60, 'num_instance': 4, 'num_workers': 8, 'optimizer': 'Adam', 'output_dir': 'logs/CUHK-PEDES/20230418_223906_iira', 'power': 0.9, 'pretrain_choice': 'ViT-B/16', 'resume': False, 'resume_ckpt_file': '', 'root_dir': './data', 'sampler': 'random', 'stride_size': 16, 'target_lr': 0, 'temperature': 0.02, 'test_batch_size': 512, 'text_length': 77, 'training': False, 'val_dataset': 'val', 'vocab_size': 49408, 'warmup_epochs': 5, 'warmup_factor': 0.1, 'warmup_method': 'linear', 'weight_decay': 4e-05, 'weight_decay_bias': 0.0}
2023-04-23 02:54:40,257 IRRA.dataset INFO: => ICFG-PEDES Images and Captions are loaded
2023-04-23 02:54:40,258 IRRA.dataset INFO: ICFGPEDES Dataset statistics:
2023-04-23 02:54:40,259 IRRA.dataset INFO: 
+--------+------+--------+----------+
| subset | ids  | images | captions |
+--------+------+--------+----------+
| train  | 3102 | 34674  |  34674   |
|  test  | 1000 | 19848  |  19848   |
|  val   |  0   |   0    |    0     |
+--------+------+--------+----------+
2023-04-23 02:54:41,221 IRRA.model INFO: Load pretrained ViT-B/16 CLIP model with model config: {'embed_dim': 512, 'image_resolution': [384, 128], 'vision_layers': 12, 'vision_width': 768, 'vision_patch_size': 16, 'context_length': 77, 'vocab_size': 49408, 'transformer_width': 512, 'transformer_heads': 8, 'transformer_layers': 12, 'stride_size': 16}
2023-04-23 02:54:48,453 IRRA.test INFO: Enter inferencing
2023-04-23 02:56:15,668 IRRA.eval INFO: 
+------+--------+--------+--------+--------+-------+
| task |   R1   |   R5   |  R10   |  mAP   |  mINP |
+------+--------+--------+--------+--------+-------+
| t2i  | 43.133 | 62.500 | 70.022 | 22.367 | 2.100 |
| i2t  | 42.377 | 66.032 | 74.889 | 20.514 | 1.833 |
+------+--------+--------+--------+--------+-------+

TEST (RSTPReid):
2023-04-23 02:58:47,112 IRRA INFO: {'GPU_ID': 0, 'MLM': True, 'alpha': 0.9, 'batch_size': 64, 'beta': 0.999, 'bias_lr_factor': 2.0, 'cmt_depth': 4, 'dataset_name': 'RSTPReid', 'distributed': False, 'eval_period': 1, 'gamma': 0.1, 'id_loss_weight': 1.0, 'img_aug': True, 'img_size': [384, 128], 'local_rank': 0, 'log_period': 100, 'loss_names': 'sdm+mlm', 'lr': 1e-05, 'lr_factor': 5.0, 'lrscheduler': 'cosine', 'masked_token_rate': 0.8, 'masked_token_unchanged_rate': 0.1, 'milestones': [20, 50], 'mlm_loss_weight': 1.0, 'momentum': 0.9, 'name': 'iira', 'num_epoch': 60, 'num_instance': 4, 'num_workers': 8, 'optimizer': 'Adam', 'output_dir': 'logs/CUHK-PEDES/20230418_223906_iira', 'power': 0.9, 'pretrain_choice': 'ViT-B/16', 'resume': False, 'resume_ckpt_file': '', 'root_dir': './data', 'sampler': 'random', 'stride_size': 16, 'target_lr': 0, 'temperature': 0.02, 'test_batch_size': 512, 'text_length': 77, 'training': False, 'val_dataset': 'val', 'vocab_size': 49408, 'warmup_epochs': 5, 'warmup_factor': 0.1, 'warmup_method': 'linear', 'weight_decay': 4e-05, 'weight_decay_bias': 0.0}
2023-04-23 02:58:47,220 IRRA.dataset INFO: => RSTPReid Images and Captions are loaded
2023-04-23 02:58:47,220 IRRA.dataset INFO: RSTPReid Dataset statistics:
2023-04-23 02:58:47,221 IRRA.dataset INFO: 
+--------+------+--------+----------+
| subset | ids  | images | captions |
+--------+------+--------+----------+
| train  | 3701 | 18505  |  37010   |
|  test  | 200  |  1000  |   2000   |
|  val   | 200  |  1000  |   2000   |
+--------+------+--------+----------+
2023-04-23 02:58:48,232 IRRA.model INFO: Load pretrained ViT-B/16 CLIP model with model config: {'embed_dim': 512, 'image_resolution': [384, 128], 'vision_layers': 12, 'vision_width': 768, 'vision_patch_size': 16, 'context_length': 77, 'vocab_size': 49408, 'transformer_width': 512, 'transformer_heads': 8, 'transformer_layers': 12, 'stride_size': 16}
2023-04-23 02:58:55,294 IRRA.test INFO: Enter inferencing
2023-04-23 02:59:05,148 IRRA.eval INFO: 
+------+--------+--------+--------+--------+--------+
| task |   R1   |   R5   |  R10   |  mAP   |  mINP  |
+------+--------+--------+--------+--------+--------+
| t2i  | 53.300 | 77.400 | 86.000 | 40.054 | 16.630 |
| i2t  | 54.700 | 79.600 | 87.400 | 35.797 | 11.013 |
+------+--------+--------+--------+--------+--------+

TEST (IIITD):2023-04-23 02:59:28,896 IRRA INFO: {'GPU_ID': 0, 'MLM': True, 'alpha': 0.9, 'batch_size': 64, 'beta': 0.999, 'bias_lr_factor': 2.0, 'cmt_depth': 4, 'dataset_name': 'IIITD', 'distributed': False, 'eval_period': 1, 'gamma': 0.1, 'id_loss_weight': 1.0, 'img_aug': True, 'img_size': [384, 128], 'local_rank': 0, 'log_period': 100, 'loss_names': 'sdm+mlm', 'lr': 1e-05, 'lr_factor': 5.0, 'lrscheduler': 'cosine', 'masked_token_rate': 0.8, 'masked_token_unchanged_rate': 0.1, 'milestones': [20, 50], 'mlm_loss_weight': 1.0, 'momentum': 0.9, 'name': 'iira', 'num_epoch': 60, 'num_instance': 4, 'num_workers': 8, 'optimizer': 'Adam', 'output_dir': 'logs/CUHK-PEDES/20230418_223906_iira', 'power': 0.9, 'pretrain_choice': 'ViT-B/16', 'resume': False, 'resume_ckpt_file': '', 'root_dir': './data', 'sampler': 'random', 'stride_size': 16, 'target_lr': 0, 'temperature': 0.02, 'test_batch_size': 512, 'text_length': 77, 'training': False, 'val_dataset': 'val', 'vocab_size': 49408, 'warmup_epochs': 5, 'warmup_factor': 0.1, 'warmup_method': 'linear', 'weight_decay': 4e-05, 'weight_decay_bias': 0.0}
2023-04-23 02:59:29,350 IRRA.dataset INFO: => IIITD Images and Captions are loaded
2023-04-23 02:59:29,350 IRRA.dataset INFO: IIITD Dataset statistics:
2023-04-23 02:59:29,350 IRRA.dataset INFO: 
+--------+-------+--------+----------+
| subset |  ids  | images | captions |
+--------+-------+--------+----------+
| train  | 15000 | 30000  |  30000   |
|  test  |  2500 |  5000  |   5000   |
|  val   |  2500 |  5000  |   5000   |
+--------+-------+--------+----------+
2023-04-23 02:59:30,290 IRRA.model INFO: Load pretrained ViT-B/16 CLIP model with model config: {'embed_dim': 512, 'image_resolution': [384, 128], 'vision_layers': 12, 'vision_width': 768, 'vision_patch_size': 16, 'context_length': 77, 'vocab_size': 49408, 'transformer_width': 512, 'transformer_heads': 8, 'transformer_layers': 12, 'stride_size': 16}
2023-04-23 02:59:37,371 IRRA.test INFO: Enter inferencing
2023-04-23 02:59:56,227 IRRA.eval INFO: 
+------+--------+--------+--------+--------+--------+
| task |   R1   |   R5   |  R10   |  mAP   |  mINP  |
+------+--------+--------+--------+--------+--------+
| t2i  | 64.560 | 82.280 | 87.060 | 72.840 | 74.712 |
| i2t  | 73.520 | 90.920 | 94.120 | 71.794 | 62.283 |
+------+--------+--------+--------+--------+--------+
