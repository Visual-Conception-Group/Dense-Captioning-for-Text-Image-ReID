Namespace(mode='train', trained=False, bidirectional=True, using_pose=False, last_lstm=False, using_noun=False, epoch=60, start_epoch=0, epoch_decay=[20, 40, 50], wd=4e-05, batch_size=64, adam_alpha=0.9, adam_beta=0.999, lr=0.001, margin=0.3, vocab_size=4750, feature_length=512, class_num=20102, part=6, caption_length_max=100, random_erasing=0.0, Save_param_every=5, save_path='./checkpoints/dual_modal/maml/model_get', GPU_id='0', device=device(type='cuda', index=0), dataset='maml', dataroot='', pkl_root='/home/zefeng/Exp/code/text-image/code by myself/data/processed_data/', test_image_num=200, data_augment=False, d_model=1024, nhead=4, dim_feedforward=2048, normalize_before=False, num_encoder_layers=3, num_decoder_layers=3, num_query=6, detr_lr=0.0001, txt_detr_lr=0.0001, txt_lstm_lr=0.001, res_y=False, noself=False, post_norm=False, n_heads=4, n_layers=2, share_query=True, ViT_layer=8, wordtype='bert')
Namespace(mode='train', trained=False, bidirectional=True, using_pose=False, last_lstm=False, using_noun=False, epoch=60, start_epoch=0, epoch_decay=[20, 40, 50], wd=4e-05, batch_size=64, adam_alpha=0.9, adam_beta=0.999, lr=0.001, margin=0.3, vocab_size=4750, feature_length=512, class_num=20102, part=6, caption_length_max=100, random_erasing=0.0, Save_param_every=5, save_path='./checkpoints/dual_modal/maml/model_get', GPU_id='0', device=device(type='cuda', index=0), dataset='maml', dataroot='', pkl_root='/home/zefeng/Exp/code/text-image/code by myself/data/processed_data/', test_image_num=200, data_augment=False, d_model=1024, nhead=4, dim_feedforward=2048, normalize_before=False, num_encoder_layers=3, num_decoder_layers=3, num_query=6, detr_lr=0.0001, txt_detr_lr=0.0001, txt_lstm_lr=0.001, res_y=False, noself=False, post_norm=False, n_heads=4, n_layers=2, share_query=True, ViT_layer=8, wordtype='bert')
Namespace(mode='train', trained=False, bidirectional=True, using_pose=False, last_lstm=False, using_noun=False, epoch=60, start_epoch=0, epoch_decay=[20, 40, 50], wd=4e-05, batch_size=64, adam_alpha=0.9, adam_beta=0.999, lr=0.001, margin=0.3, vocab_size=4750, feature_length=512, class_num=20102, part=6, caption_length_max=100, random_erasing=0.0, Save_param_every=5, save_path='./checkpoints/dual_modal/maml/model_get', GPU_id='0', device=device(type='cuda', index=0), dataset='maml', dataroot='', pkl_root='/home/zefeng/Exp/code/text-image/code by myself/data/processed_data/', test_image_num=200, data_augment=False, d_model=1024, nhead=4, dim_feedforward=2048, normalize_before=False, num_encoder_layers=3, num_decoder_layers=3, num_query=6, detr_lr=0.0001, txt_detr_lr=0.0001, txt_lstm_lr=0.001, res_y=False, noself=False, post_norm=False, n_heads=4, n_layers=2, share_query=True, ViT_layer=8, wordtype='bert')
Model_size: 212.67774M
beta lr:0.0001
beta lr:0.0001
beta lr:0.001
beta lr:0.001
beta lr:0.001
alpha lr:0.0001
alpha lr:0.0001
alpha lr:0.001
alpha lr:0.001
alpha lr:0.001
Namespace(mode='train', trained=False, bidirectional=True, using_pose=False, last_lstm=False, using_noun=False, epoch=60, start_epoch=0, epoch_decay=[20, 40, 50], wd=4e-05, batch_size=64, adam_alpha=0.9, adam_beta=0.999, lr=0.001, margin=0.3, vocab_size=4750, feature_length=512, class_num=20102, part=6, caption_length_max=100, random_erasing=0.0, Save_param_every=5, save_path='./checkpoints/dual_modal/maml/model_get', GPU_id='0', device=device(type='cuda', index=0), dataset='maml', dataroot='', pkl_root='/home/zefeng/Exp/code/text-image/code by myself/data/processed_data/', test_image_num=200, data_augment=False, d_model=1024, nhead=4, dim_feedforward=2048, normalize_before=False, num_encoder_layers=3, num_decoder_layers=3, num_query=6, detr_lr=0.0001, txt_detr_lr=0.0001, txt_lstm_lr=0.001, res_y=False, noself=False, post_norm=False, n_heads=4, n_layers=2, share_query=True, ViT_layer=8, wordtype='bert')
Model_size: 212.67774M
beta lr:0.0001
beta lr:0.0001
beta lr:0.001
beta lr:0.001
beta lr:0.001
alpha lr:0.0001
alpha lr:0.0001
alpha lr:0.001
alpha lr:0.001
alpha lr:0.001
Namespace(mode='train', trained=False, bidirectional=True, using_pose=False, last_lstm=False, using_noun=False, epoch=60, start_epoch=0, epoch_decay=[20, 40, 50], wd=4e-05, batch_size=64, adam_alpha=0.9, adam_beta=0.999, lr=0.001, margin=0.3, vocab_size=4750, feature_length=512, class_num=20102, part=6, caption_length_max=100, random_erasing=0.0, Save_param_every=5, save_path='./checkpoints/dual_modal/maml/model_get', GPU_id='0', device=device(type='cuda', index=0), dataset='maml', dataroot='', pkl_root='/home/zefeng/Exp/code/text-image/code by myself/data/processed_data/', test_image_num=200, data_augment=False, d_model=1024, nhead=4, dim_feedforward=2048, normalize_before=False, num_encoder_layers=3, num_decoder_layers=3, num_query=6, detr_lr=0.0001, txt_detr_lr=0.0001, txt_lstm_lr=0.001, res_y=False, noself=False, post_norm=False, n_heads=4, n_layers=2, share_query=True, ViT_layer=8, wordtype='bert')
Model_size: 212.67774M
beta lr:0.0001
beta lr:0.0001
beta lr:0.001
beta lr:0.001
beta lr:0.001
alpha lr:0.001
Epoch: 1/60 Setp: 50, ranking_loss: 28.60, id_loss: 20.70, ranking_loss_dict: 30.33, id_loss_dict: 21.18,ranking_loss_dict_text: 27.18, ranking_loss_dict_image: 21.54,pred_i2t_local: 0.003 pred_t2i_local 0.000
Epoch: 1/60 Setp: 100, ranking_loss: 26.73, id_loss: 20.20, ranking_loss_dict: 28.95, id_loss_dict: 20.13,ranking_loss_dict_text: 20.17, ranking_loss_dict_image: 15.96,pred_i2t_local: 0.000 pred_t2i_local 0.000
Epoch: 1/60 Setp: 150, ranking_loss: 24.34, id_loss: 18.53, ranking_loss_dict: 31.04, id_loss_dict: 18.85,ranking_loss_dict_text: 19.57, ranking_loss_dict_image: 10.27,pred_i2t_local: 0.003 pred_t2i_local 0.000
Epoch: 1/60 Setp: 200, ranking_loss: 20.90, id_loss: 18.61, ranking_loss_dict: 28.92, id_loss_dict: 18.78,ranking_loss_dict_text: 17.89, ranking_loss_dict_image: 8.36,pred_i2t_local: 0.000 pred_t2i_local 0.000
Epoch: 1/60 Setp: 250, ranking_loss: 18.31, id_loss: 19.17, ranking_loss_dict: 25.79, id_loss_dict: 19.36,ranking_loss_dict_text: 16.52, ranking_loss_dict_image: 4.67,pred_i2t_local: 0.000 pred_t2i_local 0.000
Epoch: 1/60 Setp: 300, ranking_loss: 17.10, id_loss: 19.06, ranking_loss_dict: 27.15, id_loss_dict: 19.71,ranking_loss_dict_text: 18.00, ranking_loss_dict_image: 5.71,pred_i2t_local: 0.000 pred_t2i_local 0.000
Epoch: 1/60 Setp: 350, ranking_loss: 17.67, id_loss: 18.41, ranking_loss_dict: 30.49, id_loss_dict: 18.71,ranking_loss_dict_text: 18.22, ranking_loss_dict_image: 3.67,pred_i2t_local: 0.000 pred_t2i_local 0.000
Epoch: 1/60 Setp: 400, ranking_loss: 18.38, id_loss: 19.38, ranking_loss_dict: 29.72, id_loss_dict: 19.28,ranking_loss_dict_text: 16.87, ranking_loss_dict_image: 5.05,pred_i2t_local: 0.000 pred_t2i_local 0.000
Epoch: 1/60 Setp: 450, ranking_loss: 17.69, id_loss: 19.32, ranking_loss_dict: 31.12, id_loss_dict: 19.75,ranking_loss_dict_text: 14.98, ranking_loss_dict_image: 4.58,pred_i2t_local: 0.000 pred_t2i_local 0.000
Namespace(mode='train', trained=False, bidirectional=True, using_pose=False, last_lstm=False, using_noun=False, epoch=60, start_epoch=0, epoch_decay=[20, 40, 50], wd=4e-05, batch_size=64, adam_alpha=0.9, adam_beta=0.999, lr=0.001, margin=0.3, vocab_size=4750, feature_length=512, class_num=20102, part=6, caption_length_max=100, random_erasing=0.0, Save_param_every=5, save_path='./checkpoints/dual_modal/maml/model_get', GPU_id='7', device=device(type='cuda', index=7), dataset='maml', dataroot='', pkl_root='/home/zefeng/Exp/code/text-image/code by myself/data/processed_data/', test_image_num=200, data_augment=False, d_model=1024, nhead=4, dim_feedforward=2048, normalize_before=False, num_encoder_layers=3, num_decoder_layers=3, num_query=6, detr_lr=0.0001, txt_detr_lr=0.0001, txt_lstm_lr=0.001, res_y=False, noself=False, post_norm=False, n_heads=4, n_layers=2, share_query=True, ViT_layer=8, wordtype='bert')
Model_size: 212.67774M
beta lr:0.0001
beta lr:0.0001
beta lr:0.001
beta lr:0.001
beta lr:0.001
alpha lr:0.001
Namespace(mode='train', trained=False, bidirectional=True, using_pose=False, last_lstm=False, using_noun=False, epoch=60, start_epoch=0, epoch_decay=[20, 40, 50], wd=4e-05, batch_size=64, adam_alpha=0.9, adam_beta=0.999, lr=0.001, margin=0.3, vocab_size=4750, feature_length=512, class_num=20102, part=6, caption_length_max=100, random_erasing=0.0, Save_param_every=5, save_path='./checkpoints/dual_modal/maml/model_get', GPU_id='7', device=device(type='cuda', index=7), dataset='maml', dataroot='', pkl_root='/home/zefeng/Exp/code/text-image/code by myself/data/processed_data/', test_image_num=200, data_augment=False, d_model=1024, nhead=4, dim_feedforward=2048, normalize_before=False, num_encoder_layers=3, num_decoder_layers=3, num_query=6, detr_lr=0.0001, txt_detr_lr=0.0001, txt_lstm_lr=0.001, res_y=False, noself=False, post_norm=False, n_heads=4, n_layers=2, share_query=True, ViT_layer=8, wordtype='bert')
Namespace(mode='train', trained=False, bidirectional=True, using_pose=False, last_lstm=False, using_noun=False, epoch=60, start_epoch=0, epoch_decay=[20, 40, 50], wd=4e-05, batch_size=64, adam_alpha=0.9, adam_beta=0.999, lr=0.001, margin=0.3, vocab_size=4750, feature_length=512, class_num=20102, part=6, caption_length_max=100, random_erasing=0.0, Save_param_every=5, save_path='./checkpoints/dual_modal/maml/model_get', GPU_id='5', device=device(type='cuda', index=5), dataset='maml', dataroot='', pkl_root='/home/zefeng/Exp/code/text-image/code by myself/data/processed_data/', test_image_num=200, data_augment=False, d_model=1024, nhead=4, dim_feedforward=2048, normalize_before=False, num_encoder_layers=3, num_decoder_layers=3, num_query=6, detr_lr=0.0001, txt_detr_lr=0.0001, txt_lstm_lr=0.001, res_y=False, noself=False, post_norm=False, n_heads=4, n_layers=2, share_query=True, ViT_layer=8, wordtype='bert')
Model_size: 212.67774M
beta lr:0.0001
beta lr:0.0001
beta lr:0.001
beta lr:0.001
beta lr:0.001
alpha lr:0.001
Namespace(mode='train', trained=False, bidirectional=True, using_pose=False, last_lstm=False, using_noun=False, epoch=60, start_epoch=0, epoch_decay=[20, 40, 50], wd=4e-05, batch_size=8, adam_alpha=0.9, adam_beta=0.999, lr=0.001, margin=0.3, vocab_size=4750, feature_length=512, class_num=20102, part=6, caption_length_max=100, random_erasing=0.0, Save_param_every=5, save_path='./checkpoints/dual_modal/maml/model_get', GPU_id='5', device=device(type='cuda', index=5), dataset='maml', dataroot='', pkl_root='/home/zefeng/Exp/code/text-image/code by myself/data/processed_data/', test_image_num=200, data_augment=False, d_model=1024, nhead=4, dim_feedforward=2048, normalize_before=False, num_encoder_layers=3, num_decoder_layers=3, num_query=6, detr_lr=0.0001, txt_detr_lr=0.0001, txt_lstm_lr=0.001, res_y=False, noself=False, post_norm=False, n_heads=4, n_layers=2, share_query=True, ViT_layer=8, wordtype='bert')
Model_size: 212.67774M
beta lr:0.0001
beta lr:0.0001
beta lr:0.001
beta lr:0.001
beta lr:0.001
alpha lr:0.001
Epoch: 1/60 Setp: 50
Epoch: 1/60 Setp: 100
Epoch: 1/60 Setp: 150
Epoch: 1/60 Setp: 200
Epoch: 1/60 Setp: 250
Epoch: 1/60 Setp: 300
Epoch: 1/60 Setp: 350
Epoch: 1/60 Setp: 400
Epoch: 1/60 Setp: 450
Epoch: 1/60 Setp: 500
Epoch: 1/60 Setp: 550
Epoch: 1/60 Setp: 600
Epoch: 1/60 Setp: 650
Epoch: 1/60 Setp: 700
Epoch: 1/60 Setp: 750
Epoch: 1/60 Setp: 800
Epoch: 1/60 Setp: 850
Epoch: 1/60 Setp: 900
Epoch: 1/60 Setp: 950
Epoch: 1/60 Setp: 1000
Epoch: 1/60 Setp: 1050
Epoch: 1/60 Setp: 1100
Epoch: 1/60 Setp: 1150
Epoch: 1/60 Setp: 1200
Epoch: 1/60 Setp: 1250
Epoch: 1/60 Setp: 1300
Epoch: 1/60 Setp: 1350
Epoch: 1/60 Setp: 1400
Epoch: 1/60 Setp: 1450
Epoch: 1/60 Setp: 1500
Epoch: 1/60 Setp: 1550
Epoch: 1/60 Setp: 1600
Epoch: 1/60 Setp: 1650
Epoch: 1/60 Setp: 1700
Epoch: 1/60 Setp: 1750
Epoch: 1/60 Setp: 1800
Epoch: 1/60 Setp: 1850
Epoch: 1/60 Setp: 1900
Epoch: 1/60 Setp: 1950
Epoch: 1/60 Setp: 2000
Epoch: 1/60 Setp: 2050
Epoch: 1/60 Setp: 2100
Epoch: 1/60 Setp: 2150
Epoch: 1/60 Setp: 2200
Epoch: 1/60 Setp: 2250
Epoch: 1/60 Setp: 2300
Epoch: 1/60 Setp: 2350
Epoch: 1/60 Setp: 2400
Epoch: 1/60 Setp: 2450
Epoch: 1/60 Setp: 2500
Epoch: 1/60 Setp: 2550
Epoch: 1/60 Setp: 2600
Epoch: 1/60 Setp: 2650
Epoch: 1/60 Setp: 2700
Epoch: 1/60 Setp: 2750
Epoch: 1/60 Setp: 2800
Epoch: 1/60 Setp: 2850
Epoch: 1/60 Setp: 2900
Epoch: 1/60 Setp: 2950
Epoch: 1/60 Setp: 3000
Epoch: 1/60 Setp: 3050
Epoch: 1/60 Setp: 3100
Epoch: 1/60 Setp: 3150
Epoch: 1/60 Setp: 3200
Epoch: 1/60 Setp: 3250
Epoch: 1/60 Setp: 3300
Epoch: 1/60 Setp: 3350
Epoch: 1/60 Setp: 3400
Epoch: 1/60 Setp: 3450
Epoch: 1/60 Setp: 3500
Epoch: 1/60 Setp: 3550
Epoch: 1/60 Setp: 3600
Epoch: 1/60 Setp: 3650
Epoch: 1/60 Setp: 3700
Epoch: 1/60 Setp: 3750
Epoch: 1/60 Setp: 3800
Epoch: 1/60 Setp: 3850
Epoch: 1/60 Setp: 3900
Namespace(mode='train', trained=False, bidirectional=True, using_pose=False, last_lstm=False, using_noun=False, epoch=60, start_epoch=0, epoch_decay=[20, 40, 50], wd=4e-05, batch_size=16, adam_alpha=0.9, adam_beta=0.999, lr=0.001, margin=0.3, vocab_size=4750, feature_length=512, class_num=20102, part=6, caption_length_max=100, random_erasing=0.0, Save_param_every=5, save_path='./checkpoints/dual_modal/maml/model_get', GPU_id='7', device=device(type='cuda', index=7), dataset='maml', dataroot='', pkl_root='/home/zefeng/Exp/code/text-image/code by myself/data/processed_data/', test_image_num=200, data_augment=False, d_model=1024, nhead=4, dim_feedforward=2048, normalize_before=False, num_encoder_layers=3, num_decoder_layers=3, num_query=6, detr_lr=0.0001, txt_detr_lr=0.0001, txt_lstm_lr=0.001, res_y=False, noself=False, post_norm=False, n_heads=4, n_layers=2, share_query=True, ViT_layer=8, wordtype='bert')
Model_size: 212.67774M
beta lr:0.0001
beta lr:0.0001
beta lr:0.001
beta lr:0.001
beta lr:0.001
alpha lr:0.001
Namespace(mode='train', trained=False, bidirectional=True, using_pose=False, last_lstm=False, using_noun=False, epoch=60, start_epoch=0, epoch_decay=[20, 40, 50], wd=4e-05, batch_size=16, adam_alpha=0.9, adam_beta=0.999, lr=0.001, margin=0.3, vocab_size=4750, feature_length=512, class_num=20102, part=6, caption_length_max=100, random_erasing=0.0, Save_param_every=5, save_path='./checkpoints/dual_modal/maml/model_get', GPU_id='7', device=device(type='cuda', index=7), dataset='maml', dataroot='', pkl_root='/home/zefeng/Exp/code/text-image/code by myself/data/processed_data/', test_image_num=200, data_augment=False, d_model=1024, nhead=4, dim_feedforward=2048, normalize_before=False, num_encoder_layers=3, num_decoder_layers=3, num_query=6, detr_lr=0.0001, txt_detr_lr=0.0001, txt_lstm_lr=0.001, res_y=False, noself=False, post_norm=False, n_heads=4, n_layers=2, share_query=True, ViT_layer=8, wordtype='bert')
Model_size: 212.67774M
beta lr:0.0001
beta lr:0.0001
beta lr:0.001
beta lr:0.001
beta lr:0.001
alpha lr:0.001
Epoch: 1/60 Setp: 50
Epoch: 1/60 Setp: 100
Epoch: 1/60
beta lr:0.0001
beta lr:0.0001
beta lr:0.001
beta lr:0.001
beta lr:0.001
alpha lr:0.001
Namespace(mode='train', trained=False, bidirectional=True, using_pose=False, last_lstm=False, using_noun=False, epoch=60, start_epoch=0, epoch_decay=[20, 40, 50], wd=4e-05, batch_size=64, adam_alpha=0.9, adam_beta=0.999, lr=0.001, margin=0.3, vocab_size=4750, feature_length=512, class_num=20102, part=6, caption_length_max=100, random_erasing=0.0, Save_param_every=5, save_path='./checkpoints/dual_modal/maml/model_get', GPU_id='7', device=device(type='cuda', index=7), dataset='maml', dataroot='', pkl_root='/home/zefeng/Exp/code/text-image/code by myself/data/processed_data/', test_image_num=200, data_augment=False, d_model=1024, nhead=4, dim_feedforward=2048, normalize_before=False, num_encoder_layers=3, num_decoder_layers=3, num_query=6, detr_lr=0.0001, txt_detr_lr=0.0001, txt_lstm_lr=0.001, res_y=False, noself=False, post_norm=False, n_heads=4, n_layers=2, share_query=True, ViT_layer=8, wordtype='bert')
Namespace(mode='train', trained=False, bidirectional=True, using_pose=False, last_lstm=False, using_noun=False, epoch=60, start_epoch=0, epoch_decay=[20, 40, 50], wd=4e-05, batch_size=64, adam_alpha=0.9, adam_beta=0.999, lr=0.001, margin=0.3, vocab_size=4750, feature_length=512, class_num=20102, part=6, caption_length_max=100, random_erasing=0.0, Save_param_every=5, save_path='./checkpoints/dual_modal/maml/model_get', GPU_id='7', device=device(type='cuda', index=7), dataset='maml', dataroot='', pkl_root='/home/zefeng/Exp/code/text-image/code by myself/data/processed_data/', test_image_num=200, data_augment=False, d_model=1024, nhead=4, dim_feedforward=2048, normalize_before=False, num_encoder_layers=3, num_decoder_layers=3, num_query=6, detr_lr=0.0001, txt_detr_lr=0.0001, txt_lstm_lr=0.001, res_y=False, noself=False, post_norm=False, n_heads=4, n_layers=2, share_query=True, ViT_layer=8, wordtype='bert')
Model_size: 212.67774M
beta lr:0.0001
beta lr:0.0001
beta lr:0.001
beta lr:0.001
beta lr:0.001
alpha lr:0.001
Epoch: 1/60 Setp: 50, ranking_loss: 48.33, id_loss: 43.61, ranking_loss_dict: 49.83, id_loss_dict: 44.36,ranking_loss_dict_text: 35.71, ranking_loss_dict_image: 35.59,pred_i2t_local: 0.000 pred_t2i_local 0.000
Epoch: 1/60 Setp: 100, ranking_loss: 39.42, id_loss: 41.23, ranking_loss_dict: 48.46, id_loss_dict: 41.77,ranking_loss_dict_text: 31.56, ranking_loss_dict_image: 24.74,pred_i2t_local: 0.000 pred_t2i_local 0.000
Epoch: 1/60 Setp: 150, ranking_loss: 31.64, id_loss: 40.76, ranking_loss_dict: 49.14, id_loss_dict: 40.26,ranking_loss_dict_text: 32.60, ranking_loss_dict_image: 16.01,pred_i2t_local: 0.000 pred_t2i_local 0.000
Epoch: 1/60 Setp: 200, ranking_loss: 31.26, id_loss: 40.99, ranking_loss_dict: 46.24, id_loss_dict: 41.09,ranking_loss_dict_text: 28.64, ranking_loss_dict_image: 14.15,pred_i2t_local: 0.000 pred_t2i_local 0.000
Epoch: 1/60 Setp: 250, ranking_loss: 30.95, id_loss: 39.02, ranking_loss_dict: 47.06, id_loss_dict: 39.09,ranking_loss_dict_text: 28.51, ranking_loss_dict_image: 11.40,pred_i2t_local: 0.000 pred_t2i_local 0.000
Epoch: 1/60 Setp: 300, ranking_loss: 29.81, id_loss: 40.82, ranking_loss_dict: 44.52, id_loss_dict: 40.97,ranking_loss_dict_text: 28.91, ranking_loss_dict_image: 9.25,pred_i2t_local: 0.000 pred_t2i_local 0.000
Epoch: 1/60 Setp: 350, ranking_loss: 32.01, id_loss: 40.42, ranking_loss_dict: 49.02, id_loss_dict: 39.81,ranking_loss_dict_text: 25.87, ranking_loss_dict_image: 9.23,pred_i2t_local: 0.000 pred_t2i_local 0.000
Epoch: 1/60 Setp: 400, ranking_loss: 24.66, id_loss: 40.28, ranking_loss_dict: 44.90, id_loss_dict: 40.04,ranking_loss_dict_text: 24.34, ranking_loss_dict_image: 5.86,pred_i2t_local: 0.000 pred_t2i_local 0.000
Epoch: 1/60 Setp: 450, ranking_loss: 24.66, id_loss: 40.29, ranking_loss_dict: 47.60, id_loss_dict: 39.79,ranking_loss_dict_text: 27.35, ranking_loss_dict_image: 7.00,pred_i2t_local: 0.000 pred_t2i_local 0.000
